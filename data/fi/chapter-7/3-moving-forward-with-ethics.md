---
path: '/fi/chapter-7/3-moving-forward-with-ethics'
title: 'Etiikan kehittäminen'
hidden: false
---

<hero-icon heroIcon='chap7'/>

<styled-text>



Jos siirrytään eettisiä ohjeita pidemmälle, miten tekoälyn etiikan pitäisi ilmetä tulevaisuudessa? Millaisia keskusteluja tekoälyn etiikasta pitäisi käydä? Entä millaisilla toimilla ja tavoilla etiikkaa pitäisi toteuttaa käytännössä? Tähän kysymykseen on vaikea vastata, mutta joitakin vihjeitä voidaan löytää tarkastelemalla, mitä tähän mennessä on jäänyt edellä käsiteltyjen tekoälyä koskevien ohjeiden ulkopuolelle.

</styled-text>


<text-box name="AuroraAI-ohjelma" icon="techIcon">

[Suomen kansallisessa tekoälyohjelmassa AuroraAI](https://vm.fi/en/national-artificial-intelligence-programme-auroraai) (2020–2022) yhdistetään nykyteknologia, hyvin suunnitellut palveluketjut ja ihmiskeskeinen lähestymistapa hyvään hallintoon. Yksi ohjelman tavoitteista on kytkeä yhteen julkisen, yksityisen ja kolmannen sektorin palveluita ja tarjota entistä tehokkaampia, joustavampia ja räätälöidympiä julkisia palveluja.

**Toiminta:**
AuroraAI-verkolla kohdistetaan alueella tarjolla olevat palvelut niitä tarvitseville nykyistä paremmin. Palvelujen räätälöinti perustuu algoritmien tuottamiin suosituksiin, jotka ovat arvioita kansalaiselle hyödyllisimmästä palvelujen yhdistelmästä.

Tiedot arvioita varten antaa kansalainen itse. Julkishallinnon tai yksityisten yritysten hallussa olevia henkilötietoja voitaisiin tulevaisuudessa käyttää myös palvelujen räätälöintiin (koska Suomi on Euroopan unionin jäsen, tämä edellyttää riittävää oikeusperustaa henkilötietojen käytölle – ks. luvussa 5 oleva yleistä tietosuoja-asetusta käsittelevä osa).

AuroraAI on filosofinen esimerkki siitä, miten teknologia vaikuttaa hallintokäytäntöihin. Perinteisesti valtion ja kansalaisen välinen vuorovaikutus on perustunut pakkoon. Valtiot edellyttävät kansalaisia tekemään tiettyjä asioita tietyllä tavalla. AuroraAI-ohjelmassa julkishallinnon ja kansalaisten välinen vuorovaikutus perustuu pakon lisäksi suosituksiin tai ehdotuksiin.

**Eettiset näkökohdat:**
AuroraAI nostaa kuitenkin esille kysymyksen näiden algoritmisten suosittelujärjestelmien vaikutuksesta julkisen sektorin palveluihin. Alkavatko algoritmit määrittää ennalta ja ohjata käyttäjien tulevaisuutta suosittelemalla tiettyjä palveluita? Perustuvatko suositukset hyvän elämän implisiittisiin ja piilotettuihin ihanteisiin? Tyrkyttävätkö nämä järjestelmät olemassa olevia ennakkoluuloja? Miten järjestelmät on rakennettu ylläpitämään ja edistämään digitaalista osallisuutta ja tasa-arvoa?

Jos tekoälyn avulla luodaan julkisia palveluja, jotka määrittelevät ennalta ”hyvinvointia” tai ”hyvää elämää” koskevat vaatimukset liian kapea-alaisesti tai sotkevat valtion tehtävät käyttää valtaa ja tarjota hyvinvointia, hyvän hallintotavan periaatteet jäävät syrjään. AuroraAI-ohjelmassa nämä huolenaiheet ja niiden merkitys on tunnustettu. Käytännön ratkaisuna on nimitetty eettinen lautakunta, joka tarjoaa foorumin ohjelmaan liittyviä eettisiä haasteita koskeville keskusteluille.


</text-box>

<styled-text>

Oikeudenmukaisuus, vastuullisuus ja läpinäkyvyys ovat nousseet etualalle tekoälyn etiikkaa koskevassa keskustelussa. Niitä vastaavat englanninkieliset sanat esiintyvät myös eettistä tekoälyä käsittelevän suurimman tieteellisen konferenssin nimessä: Conference on Fairness, Accountability, and Transparency eli FAccT. Kuten AuroraAI osoittaa, apua, hyvinvointia sekä valtion ja kansalaisten välisiä suhteita koskevat kysymykset ovat kuitenkin moraalisia peruskysymyksiä. Niitä olisi pohdittava kaikissa valtioissa, jotka pyrkivät hyödyntämään tekoälyä julkisen sektorin palveluissaan.

Nämä arvot eivät kuitenkaan usein näy eettisissä ohjeissa. Miltä sitten näyttäisi, jos tekoälyn etiikkaa tarkasteltaisiin hoivaetiikan näkökulmasta? Hoivaetiikan mukaan on otettava huomioon yksilöiden väliset monimutkaiset ja keskinäiset riippuvuudet sekä se, miten toimien seuraukset leviävät ja vaikuttavat heikoimmassa asemassa oleviin ja miten luonto ja ekologia kietoutuvat näihin prosesseihin.

</styled-text>

<text-box name="Tekoälyjärjestelmän anatomia" icon="techIcon">

Esimerkki edellä esitetyn mukaisesta kartoituksesta on tutkijoiden Crawfordin ja Jolerin luomassa kaaviossa [Anatomy of An AI System](https://anatomyof.ai/img/ai-anatomy-map.pdf). Kaaviossa esitetään täydellinen kuvaus tekoälyjärjestelmän luomiseen tarvittavista monimutkaisista vuorovaikutuksista. Kaavio kattaa ohjelmistojen lisäksi tekoälyjärjestelmän luomiseen liittyvät materiaaliprosessit, markkinat, infrastruktuurit ja geologiset prosessit. Tämä paljastaa eettisesti merkityksellisiä näkökohtia, jotka muutoin jäisivät hämärään tekoälyn etiikan linssin läpi tarkasteltuina. Tällaisia ovat esimerkiksi kaivostoiminnasta aiheutuvat ekologiset vahingot ja tietojenkäsittelyn työolot.

</text-box>

<styled-text>

Siirryttäessä uusista näkökulmista uusiin käytäntöihin on syytä tarkastella, miten kansalaisten ja kansalaisyhteiskunnan sekä yritysten olisi osallistuttava entistä oikeudenmukaisemman tekoälyn luomiseen. Eettisen tekoälyn luominen käytännössä tarkoittaa siirtymistä hyvien aikomusten julkaisemisesta niihin moniin tapoihin, joilla yhteiskunnalliset toimijat voivat osallistua erilaisten tulevaisuuksien toteuttamiseen.

</styled-text>
<text-box>

Tarkastellaan toisena esimerkkinä AlgorithmWatchia. AlgorithmWatch seuraa Euroopassa toteutettavia julkisia ja yksityisiä tekoälyhankkeita, analysoi niiden seurauksia ja julkaisee tietoa siitä, miten ne etenevät ja miten monin tavoin ne vaikuttavat yhteiskuntaan. Yhdistyneessä kuningaskunnassa kansalaistoiminta on ilmennyt myös mielenosoituksina, kun covid-19-pandemia vaikeutti kokeiden järjestämistä ja arvosanojen antamiseen käytettiin ennustavia algoritmeja.

</text-box>

<styled-text>

Ada Lovelace Instituten johtaja Carly Kind kutsuu tätä tekoälyn etiikan kolmanneksi aalloksi ja esittää, että olemme siirtymässä uuteen yhteiskunnallisen sitoutumisen muotoon:

* ”Tekoälyn etiikan kolmannen aallon aikana hollantilainen tuomioistuin on lopettanut algoritmisen petosten havaitsemisjärjestelmän toiminnan, opiskelijat ovat lähteneet Yhdistyneessä kuningaskunnassa kaduille protestoimaan algoritmien avulla päätettyjä tenttituloksia vastaan ja yhdysvaltalaiset yritykset ovat rajoittaneet vapaaehtoisesti kasvojentunnistusteknologiansa myyntiä. Tämä vie meidät periaatteellisia ja teknisiä kysymyksiä pidemmälle käytännön mekanismeihin, joilla korjataan vallan epätasapainoa ja saavutetaan yksilöllinen ja yhteiskunnallinen oikeudenmukaisuus.”
>**-Carly Kind**

## Loppupäätelmä: nyt on sinun vuorosi

Tekoälyjärjestelmiä koskevat eettiset kysymykset liittyvät tekoälyjärjestelmän elinkaaren kaikkiin vaiheisiin. Elinkaaren ymmärretään tässä käsittävän kaiken tutkimuksesta, suunnittelusta ja kehittämisestä käyttöönottoon ja käyttöön, mukaan lukien ylläpito, toiminta, kauppa, rahoitus, seuranta ja arviointi, validointi, käytön päättyminen, purkaminen ja lopettaminen.

Tässä yhteydessä tekoälyalan toimijat voidaan määritellä toimijoiksi, jotka osallistuvat vähintään yhteen tekoälyn elinkaaren vaiheeseen. Toimijat voivat olla luonnollisia henkilöitä tai oikeushenkilöitä, kuten tutkijoita, ohjelmoijia, insinöörejä, datatieteilijöitä, loppukäyttäjiä, suuria teknologiayrityksiä, pk-yrityksiä, startup-yrityksiä, korkeakouluja tai julkisyhteisöjä.

</styled-text>

<text-box>

* Tekoälyjärjestelmät nostavat esille eettisiä kysymyksiä, jotka koskevat muun muassa niiden vaikutusta päätöksentekoon, tasa-arvoon, polarisaatioon ja hyvinvointiin.

* Tekoälyjärjestelmät vaikuttavat moniin yhteiskunnan osa-alueisiin, kuten työllisyyteen ja työvoimaan, sosiaaliseen vuorovaikutukseen, terveydenhuoltoon, koulutukseen, asekehitykseen, liikenteeseen ja mediaan.

* Tekoälyjärjestelmien yhteydessä on käsiteltävä muun muassa sananvapautta, tiedonsaantioikeutta, yksityisyydensuojaa, demokratiaa ja syrjintää.

* Tekoälyjärjestelmät voivat myös muuttaa ihmisen kokemusta, uhmata ihmisen toimijuutta, herättää huolta tietolähteiden luotettavuudesta ja kyseenalaistaa perustavanlaatuisen ihmisarvon ihanteen.

</text-box>

Tekoäly kehittyy nopeasti. Vaikka kukaan ei voi sanoa varmasti, miten tekoäly vaikuttaa elämäämme tulevaisuudessa, voimme silti vaikuttaa asiaan. Kuten useimpiin kehittyviin teknologioihin, tekoälyyn liittyy todellisia riskejä. Jos tekoälyä kehitetään ja käytetään eettisesti kestävällä tavalla, tekoälyllä voi kuitenkin olla monia myönteisiä seurauksia – ei vain yksilöille tai yhteiskunnille, vaan koko maapallolle. Kehityksen suunta riippuu kuitenkin vain meistä.

Valinta, ei sattuma, määrää kohtalosi.”
>**-Aristotle**

<img src="./p-p-f-01.svg" alt="Future"> </img>

<quiz id="4f7e90d7-09d7-5c57-ac16-664b31e522a4"> </quiz>

<quiz id="9371cb46-af42-58b9-9cfc-73adffabf2e1"> </quiz>

<quiz id="bf311283-cb4c-567b-94c2-bb09e0740919"> </quiz>

<quiz id="5407508c-8d42-5161-904c-2f4b54885596"> </quiz>
