---
path: '/fi/chapter-4/1-transparency-in-ai'
title: 'Tekoälyn läpinäkyvyys'
hidden: false
---

<hero-icon heroIcon='chap4'/>

### Läpinäkyvyyden periaate

Kuvittele kasvojentunnistusjärjestelmä nimeltä MYFACE. MYFACE-järjestelmää käytetään lentokentällä turvatarkastuksiin. Yleensä järjestelmä toimii virheettömästi, mutta eräänä päivänä se alkaa luokitella ihmisiä väärin mahdollisesti vaarallisiksi. Tämän vuoksi useita viattomia ihmisiä pidätetään. Olisiko tärkeää tietää, miksi järjestelmä teki kaikki nämä virheet? Pitäisikö meidän pystyä selittämään, miksi se teki virheitä? Entä miksi tällä olisi merkitystä?

<img src="./myface.svg" alt="myface" width="400px"> </img>

<styled-text>

Jotkin nykyiset koneoppimisjärjestelmät ovat niin kutsuttuja ”mustan laatikon” järjestelmiä, mikä tarkoittaa, että emme oikeastaan näe, miten ne toimivat. Tämä ”läpinäkymättömyys” tai näkyvyyden puute voi olla ongelma, jos näitä järjestelmiä käyttämällä tehdään yksilöihin vaikuttavia päätöksiä.

Yksilöillä on oikeus tietää, miten ratkaisevia päätöksiä tehdään – kuten päätöksiä siitä, kenen lainahakemus hyväksytään, kuka pääsee ehdonalaiseen ja kuka palkataan. Tämä on saanut monet vaatimaan ”läpinäkyvämpää tekoälyä”.

### Tekoälyn läpinäkyvyys


Läpinäkyvyys on järjestelmän ominaisuus, jonka avulla voidaan saada tiettyjä tietoja järjestelmän sisäisestä toiminnasta. Se, mitä tietoja saadaan ja ovatko ne eettisesti merkityksellisiä, riippuu lähinnä siitä eettisestä kysymyksestä, johon yritämme vastata. Läpinäkyvyys itsessään on eettisesti neutraalia, eikä se ole eettinen käsite. Sen sijaan läpinäkyvyys on ihanne. Läpinäkyvyys voi ilmetä monin eri tavoin, ja se voi olla ratkaisu taustalla oleviin eettisiin kysymyksiin. Tässä mielessä läpinäkyvyys on merkityksellistä ainakin seuraavien kolmen seikan kannalta:

**1) Päätösten perustelut.** Hyvä hallintotapa edellyttää julkisella ja yksityisellä sektorilla sitä, että päätökset eivät ole mielivaltaisia. Tämä pätee kaikenlaiseen päätöksentekoon, jolla on eettisesti tai oikeudellisesti merkityksellinen vaikutus yksilöihin. Se, että päätökset eivät ole mielivaltaisia, tarkoittaa mahdollisuutta saada perustelut sille, miksi päätös tehtiin ja millä perusteilla se tehtiin. Lisäksi erityisesti julkishallinnon osalta mahdollisuus riitauttaa päätöksiä ja hakea niihin muutosta on ratkaisevan tärkeä. Tämä tarkoittaa mahdollisuutta vaatia vääryyksien oikaisemista.

**2) Oikeus tietää.** Ihmisoikeuksien mukaan ihmisillä on oikeus saada selvitys siitä, miten päätökset on tehty, jotta he voivat säilyttää aidon toimijuutensa, vapautensa ja yksityisyytensä (lisätietoa ihmisoikeuksista on luvussa 5). Vapaus edellyttää oikeutta saada vastauksia esimerkiksi seuraaviin kysymyksiin: Miten minua seurataan? Millaisia päätelmiä minusta tehdään? Entä miten minusta on tarkalleen ottaen tehty päätelmiä?

**3) Moraalinen velvollisuus ymmärtää tekojen seuraukset**. Yhteisönä meillä on myös vastuu riskienhallinnasta. Meillä on kohtuulliseen tasoon asti moraalinen velvollisuus ymmärtää ja ennustaa sellaisten teknologioiden seuraukset, joita luomme maailmaan. Toisin sanoen ”emme voi ymmärtää nyt, mitä se tulevaisuudessa tekee” ei ole pätevä peruste haittaa aiheuttavan järjestelmän käyttöönotolle. Sen sijaan moraalinen velvollisuutemme on selvittää mahdolliset riskit.

Kaikki edellä esitetyt kolme kohtaa voidaan tiivistää riittävien tietojen saamista koskevaksi vaatimukseksi. Tiedämmekö, onko tämä algoritminen päätös perusteltu ja missä määrin se on perusteltu? Tiedänkö, miten minusta tehdään päätelmiä? Missä määrin olen vastuussa järjestelmän toimista, ja kuinka paljon minun pitäisi tietää järjestelmän sisäisestä toiminnasta voidakseni kantaa kyseisen vastuun?

</styled-text>
