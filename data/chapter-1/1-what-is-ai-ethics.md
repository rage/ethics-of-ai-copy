---
path: '/chapter-1/1-what-is-ai-ethics'
title: ' What is AI Ethics?'
hidden: false
---

<text-box variant='Intro' name='Learning objectives'>

- Learn what is AI Ethics
- Understand the role of ethical guidelines in AI
- Understand how AI ethics differs from roboethics

</text-box>


## A Shoppers's Guide to Ethics

In this course, we'll take a look at the ethical issues related to contemporary AI,  open up their background  in philosophy and give them an interpretation in terms of computer science.  The goal of course is to develop your skills for ethical thinking.
You should take this course as a shopper´s guide on the design, implementation and use of AI in ethically sustainable way.
In this first section, we'll become familiar with the basic concepts of AI ethics by looking into its definition and some examples.

## What is Ai Ethics
What is ethics? From a philosophical point of view, ethics seeks to resolve questions like ‘what is good or bad?”, “what is right - what is wrong”, ‘what is justice, well-being or equality’ by using philosophical tools.  Ethics involves systematizing, defending, and recommending concepts of right and wrong conduct by using conceptual analysis, thought experiments, and  argumentation. (If you want to know more about philosophical reasoning, see this video by Crash Course Philosophy.)

Ethics can be divided to three major sub-fields:
- Meta-ethics studies the meaning ethical concepts, the existence of ethical entities (ontology) and the possibility of ethical knowledge (epistemology).
- Normative ethics concerns the practical means of determining a moral course of action
- Applied ethics concerns what a moral agent is obligated (or permitted) to do in a specific situation or a particular domain of action.
AI Ethics is a subfield of the “applied ethics”. However, as a very young research field it is still a developing.


## On Ethical Guidelines

In the past years,  research institutions, companies, countries, public sector organizations and ad hoc committees - such as HLEG - have published principles and guidelines for “ethical artificial intelligence”.

Nowadays, there are over 165 different sets of these principles.  As things stand, these principles or reports for ethical AI are instances of “non-legislative policy instruments”.  Unlike legal regulations these guidelines are not legally binding. Instead, they are - or are hoped to turn out to be -  persuasive in nature.

Naturally, just the overall amount - over 165 sets of principles - demonstrate the strong interest to develop AI and AI-based practices in ethically sustainable way. Although the lack of legal status, still these principles seem to have practical influence on decision-making in public sector governance, in companies and many other organisations. Simultaneously,  there are reasons to be concerned about the future impact of ethics on AI development and governance.

Despite an agreement that AI should be developed and applied in  ‘ethically’ sustainable ways, depending on the source the meaning of  ‘ethical AI’ varies. Moreover, there are different views on the ethical requirements, their technical interpretation and best practices that are needed for implementing ethically acceptable AI in practice.

According to recent meta-analyses (Jobin & al, 2019), AI ethics has seemingly converged on a set of five principles;  non-maleficence,  responsibility or accountability, transparency and explainability, justice and fairness, and privacy and security.

<text-box variant="hint" name="INFOBOX: DEFINITIONS">

- non-maleficence
- responsibility or accountability
- transparency and explainability
- justice and fairness
- privacy and security

</text-box>

OR

<text-box variant="hint" name="INFOBOX: DEFINITIONS">

1. How could we use AI for good, and not for causing  harm (the principle of non-maleficance)
2. Who should be blame when AI causes harm? (the principle of accountability)
3. Should we understand what, and why AI does whatever it does? (The principle of transparency)
4. Should AI be fair, non-discriminative and promote equality? (The principle of fairness)
5. Should AI respect, and promote human rights? (The principle of respecting basic human rights)

</text-box>

## Examples of Ethical Principles

- HLEG: Trustworthy AI
- EU: Context and Implementation
- Rome call for ethical AI
- Microsoft

## AI Ethics vs Roboethics (was Criticism)

<text-box variant='Intro' name='The Traditional Fields of AI Ethics'>

Infobox: The Traditional Fields of AI Ethics
Traditionally AI ethics has taken to mean two things; Machine Ethics and Roboethics.
Machine ethics is, roughly, a practical research area involving the modelling and implementation of artificial moral agents. Machine ethics is designing ethics for machines, not for the human use of machines.  It is based on a presupposition that machines will make ethically relevant choices, and can be even considered possibly as ethical agents (Anderson and Anderson 2007) or ‘autonomous moral agents’ (van Wynsberghe and Robbins forthcoming).
As practical research, machine ethics has several research goals, such as the development of ethically responsive autonomous vehicles, or of automated advisers for clinicians on medical ethics issues. Moreover, the more long-term objective of machine ethics is to design the ethical codes for perhaps even ‘genuinely’ moral autonomous agents.

</text-box>

<text-box variant='Intro' name=' Asimov´s laws'>
Isaac Asimov proposed ‘three laws of robotics’ (Asimov 1942):
1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.
2. A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.
3. A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.”
Machine ethics has traditionally been contrasted with “roboethics”. Roboethics studies the moral behavior of humans as they design, construct, use and treat such beings.
However, in this course we´ll adopt a broader view on the ethics of AI, and characterize it in terms of development, design and implementation of the ethically sustainable development and use of new technologies. In what follows, the ethics of Ai will be divided to three branches: (i) Ethics for AI, which includes the machine ethics, (II) Ethics in Design of AI, and (III) Ethics for Designers of AI.

</text-box>
