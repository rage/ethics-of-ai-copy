---
path: '/chapter-1/4-an-ethical-framework-for-ai-ethics'
title: 'An ethical framework for ai ethics'
hidden: false
---

Traditionally, technology development has typically revolved around the functionality, usability, efficiency
and reliability of technologies. However, AI technology needs a broader discussion on its societal
acceptability. It impacts on moral (and political) considerations. It shapes individuals, societies and their
environments in a way that has ethical implications.

The interpretation of ethically relevant concepts can change with technologies (consider what “privacy”
meant before social media?). Furthermore, when new technologies are introduced, users often apply them
for purposes other than those originally intended. This reforms the ethical landscape, and forces one to
reflect and analyse the ethical basis of technology over and over again.

## Ethical frameworks

Ethical frameworks are attempts to build consensus around values and norms that can be adopted by a
community – whether that’s a group of individuals, citizens, governments, businesses within the data
sector and other stakeholders.

Various organisations have participated in developing an ethical framework for AI. Naturally, their views
differ in some respects, but there’s also been an emerging consensus to them. According to a recent study
(Jobin et al 2019), AI ethics has quite rapidly converged on a set of five principles; non-maleficence,
responsibility or accountability, transparency and explainability, justice and fairness, and respect of various
human rights, such as privacy and security.

<text-box variant="hint" name="The five principles of AI ethics answer different questions and focus on different values:">

1. Should we use AI for good and not for causing harm? (the principle of beneficence/ non-
maleficance)
2. Who should be blamed when AI causes harm? (the principle of accountability)
3. Should we understand what, and why AI does whatever it does? (The principle of transparency)
4. Should AI be fair or non-discriminative? (The principle of fairness)
5. Should AI respect and promote human rights? (The principle of respecting basic human rights)

</text-box>

The rest of this course will focus on these principles of AI ethics. We will analyse what these concepts imply
and how they can be interpreted, in the fashion of traditional philosophy: concept analysis. We will also
look at how these concepts are being applied in practice. We´ll also discuss their problems and mention
some open questions regarding these principles.

In the last section of the course, we will look at the project of AI ethics as a whole. We will be asking the
“cui bono” question: who is AI ethics for, and who or what is left out?

Lastly, we want to note that when speaking of AI and “the social”, AI ethics is the first to come up. There
are other theoretical frames for looking at ethical codes for algorithmic, data-driven systems. For example,
questions of the social implications of AI come up in fields like political economy (Sadowski), algorithmic
cultures (Seaver), gender studies (Keyes), media studies (van Dijk), amongst numerous others.
Correspondingly, the cognitive and psychological aspects of human-machine interaction complicates the
question of appropriate ethical framework for AI even more. Simply, there is a lot more to AI ethics than
just data or algorithm ethics.
