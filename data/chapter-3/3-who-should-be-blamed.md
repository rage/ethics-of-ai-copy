---
path: '/chapter-3/3-who-should-be-blamed'
title: 'Who should we blame, and for what?'
hidden: false
---

## Moral Agency

In ethics, accountability is closely related to the concept of “moral agency”. A moral agent is "an
agent who is capable of acting with reference to right and wrong." Importantly, only moral agents
are morally responsible for their actions.

**Actions and omissions**

Philosophically, a moral agent is primarily responsible for their own actions (“acts”). Sometimes agents are also responsible for not-doings, “omissions”. So, if I kill someone, I am responsible for that act. If I just let someone die, I am responsible for not-helping (omission), even if I would not actively kill.

Omissions and actions are not morally equal. It is morally less bad to omit a thing than to perform an act: It is worse to actively kill someone than to let them die. But this doesn’t make omissions morally right. However, we cannot be responsible for all of the things we do not do. Instead, we are responsible for only those things which we’ve deliberately and knowingly chosen to do or omit.

**Autonomy**
According to philosophers, moral responsibility requires 1) moral autonomy and 2) the ability to evaluate the consequences of actions. “Moral autonomy” means the agent’s capacity to impose the moral code on oneself in a self-governed way.  Further, autonomy requires:


1. the capacity to rule oneself without manipulation by others and the ability to act, without
external or internal contsraints (see Dworkin 1989).

2. the authenticity of the desires (values, emotions, etc) that move one to act. **LINK TO LITERATURE**.

3. sufficient cognitive skills. An agent must be able to evaluate, to predict and to compare
consequencies of her actions and, also, to estimate motives that drive action by using
ethically meaningful criteria.

<text-box variant="hint" name="Moral responsibility">

Immanuel Kant is one of the most famous moral philosophers in Western thought. For Immanuel Kant, practical reason — our ability to use reasons to choose our own actions — presupposes that we are free.  It means that actions are based on our own will to utilize a moral law to guide our decisions. For Kant, and Kantians, this capacity to impose upon ourselves moral law is the ultimate source of all moral value.

So, according to Kant, we owe to ourselves moral respect in virtue of our autonomy. But insofar as this capacity depends in no way on anything particular or contingent about ourselves, we owe similar respect to all other persons in virtue to their capacity. That means (via the second formulation of Kant´s famous [Categorical Imperative](https://en.wikipedia.org/wiki/Categorical_imperative)), we are obliged to act out of fundamental respect for other persons in virtue of their autonomy. In this way, autonomy serves as both a model of practical reason in the determination of moral obligation and as the feature of other persons deserving moral respect from us. (For further discussion, see Immanual Kant and moral philosophy.)

</text-box>

**Actions and omissions**

From a moral point of view, a moral agent is primarily responsible for their own actions (“acts”). Sometimes agents are also responsible for actions which they do not actually do. These are called “omissions”.

Obviously, agents cannot be responsible for all of the things they do not do. That’s why  philosophers emphasize that agents are responsible for only those things which they´ve deliberately chosen to do or to omit. However, omissions and actions are not morally equal. It is morally less bad to omit a thing than to perform an act. In other words, it’s simply worse to actively kill someone than to let them die.

<text-box variant="hint" name="A story">

Helsinki  -- is it moral not to help people by using AI-methods, even if those methods may violate the privacy? Can you help someone against their own will?

</text-box>

**Accountability and transparency**

Who should we blame when AI systems don’t work as intended or make a mistake? Accountability is a relative notion: an actor is responsible for a specific action or omission, but the quality of responsibility is dependent on the stakeholder. We are not universally responsible. But it has turned out to be really difficult to develop a set of criteria for specific responsibilities. In many countries, there is an on-going debate on this question. Many international actors, such as European Union and G7 have addressed this as an open challenge (REFS).

<text-box variant="hint" name="Different approaches">

Accountability is related to other issues, such as transparency ([Chapter 4](https://ethics-of-ai.now.sh/). Accountability is primarily a legal and ethical obligation on an individual (or organisation) to accept responsibility for the use of AI systems, and to disclose the results in a transparent manner.

</text-box>
