---
path: '/chapter-3/1-defining-accountability'
title: 'Defining accountability'
hidden: false
---



<text-box variant='Intro' name='Learning objectives'>

1.  Defining accountability
2.  Agents, Actions and Omissions
3.  Moral machines

</text-box>

## **1. Defining accountability**

From estimating taxation to determining social benefits or health insurance premiums, AI and algorithmic systems in general are increasingly being used for decision-making. Algorithms can be used to promote fairness, equality and well-being.  Paradoxically, they can also discriminate,  violate human rights and be unfair.

 [Examples](https://ethics-of-ai.now.sh/)

Obviously, current AI applications are just computer programs, not morally responsible agents (they have no moral agency by themselves, meaning they are not capable of acting with reference to right and wrong). Instead, the moral abilities of contemporary AI systems are based on the users’ or developers’ intentions and aims.
That said, algorithms still raise a growing challenge for legislators, authorities and policy makers in many countries. They force us to ask the question: if algorithmic systems make mistakes, who should we blame – and on what grounds?

<text-box variant="hint" name="Definitions, definitions">

**An automated systems** typically runs within a well-defined set of parameters and are very restricted in what tasks they can perform. The decisions made or actions taken by an automated system are based on predefined heuristics.

**An autonomous system** learns and adapts to dynamic environments, and evolves as the environment around it changes. The data it learns and adapts to may be outside what was contemplated when the system was deployed.

**Data-based decision making** uses collected data to make decisions. This can be done either automatically or by a human analyst.
</text-box>

## **What is “accountability”?**

 “Accountability” is about an acknowledgement of responsibility for actions, decisions
and products. In the field of AI ethics, there exist three main areas of accountability,:

Accountability as a feature of the AI system itself.
Accountability as the question of determining responsibility. Which individuals (or groups) are accountable for the impact of algorithms or AI? Who is responsible for what effect within the overall socio-technical system?
Accountability as a feature of the societal system that develops, produces, and uses AI.

Accountability presupposes a “power-relation”. It determines who is in control and who is to be blamed. Responsibility may be a legal or an ethical question.

<text-box variant="hint" name="">

**Legally**, an actor is responsible for an event when a legal system is liable to penalise that actor for that event.

**Morally**, an actor is responsible for an act if they can be blamed for that action.

<text-box>

Legal and moral responsibility are two different things. They do not always coincide; an agent can be legally responsible even if they were not morally responsible, and vice versa. We’ll discuss more about what moral responsibility means in practice in section II.
