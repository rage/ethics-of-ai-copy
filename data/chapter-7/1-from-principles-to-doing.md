---
path: '/chapter-7/1-from-principles-to-doing'
title: 'From principles to doing'
hidden: false
---

<hero-icon heroIcon='chap6'/>

<styled-text>

<p style="color:red;">In this section, we take a reflective look at the project of AI ethics as a whole – this requires us to look into the making and doing of AI ethics as a phenomenon. </p>

<br>

“[Ethics] plays the role of a bicycle brake on an intercontinental airplane”
-Ulrike Beck, 1988

In this section, we’ll take a reflective look at the whole project of AI ethics. This means looking at the making and doing of AI ethics as a phenomenon. AI ethics is a project with diverse members who have differing stakes – and it produces contents and discussions that can be analyzed as cultural products. That is, AI ethics is created by certain people, at a certain time, for certain purposes. But what are these purposes, and is AI ethics achieving its goals?

To date, most ethical discussions regarding AI systems have focused on defining principles to prevent risks. National policies and various initiatives have been made on the basis of these discussions. AlgorithmWatch, a Berlin-based organization, maintains a repository of published AI ethics guidelines, with over 160 collected so far. It is hard to find any actor in AI these days that does not point to their own set of guidelines as evidence of their ethical engagement.

Although ethical principles can shape the development and implementation of ethics-based policy measures and legal norms, empirical studies suggest that guidelines have little impact on the practices surrounding AI development:

“Despite its stated goal, we found no evidence that the ACM code of ethics influences ethical decision-making. Future research is required to identify interventions that do influence decision-making, such as by helping developers identify parallels between their decisions and infamous software news stories.”
-McNamara et al. (2018)

</styled-text>


<text-box name="What is ethics-washing?">

Often, there is a lack of real implementation mechanics and assessment practices that would turn guidelines into more ethically aware development. Also lacking are mechanisms to halt ethically suspect projects. According to critics, many of the activities around the discussion of AI ethics should therefore be described as “ethics-washing”.

**Technical fixes**

In ethics washing, the ethical questions are typically reduced into the sets of narrow, technologized concepts. Ethical questions are seen as technical questions that can be solved by technical fixes alone. This, however, obscures the larger, often socio-technical problems. For example, remembering our discussion on fairness in chapter 6, the effort to de-bias datasets by adding more diverse representation may fulfill a mathematical definition of fairness. But if that dataset only serves to create more effective tools of surveillance and subjugation, then our conception of ethics has failed to capture what it means to be just.

**A shared project: an ideal future**

AI is often described as a shared, collective project: an ideal future which humanity cooperatively strives for, encountering technical obstacles to ethics that can be overcome with technical fixes. This is evidenced most clearly in the positioning of AI as something outside of social relations, and the depiction of humanity as a unanimous polity, in phrases like “AI should respect human values” or “the human aspect in AI”.

A more appropriate image positions AI, like any other technology, in the spaces between human collectives and into the struggles and power relations among us. This means also admitting that there are plainly malicious actors and explicitly malicious uses of AI. There are several areas – the military use of AI in warfare, automated propaganda and disinformation campaigns, social control and sorting, surveillance, or the use of AI for manipulation – where this can occur.


</text-box>

<img src="./p-p-f-01.svg" alt="Future"> </img>

