---
path: '/chapter-7/1-moving-forward-with-ethics'
title: 'Moving forward with ethics'
hidden: false
---

### III. Moving forward with ethics

Moving beyond ethical guidelines, how should AI ethics manifest in the future? What kind of conversations around the ethics of AI should we have, and what kind of activities and ways of doing ethics should be taken into practice? This is a difficult question to answer, but some hints can be found from looking at what is left outside the scope of the AI ethics guidelines we have been discussing so far.


<text-box name="The AuroraAI program">

The Finnish National Artificial Intelligence Program AuroraAI (2020–2022) combines contemporary technology, well-designed service chains and a human-centric approach to good governance. One of its objectives is to link together public, private and third sector services and provide more efficient, flexible and tailored public services.

**How it works**
In the AuroraAI network, a person’s needs are better matched to services available in a specific area. This tailoring of services is based on algorithmically produced  recommendations. These recommendations are estimates of the most useful combination of services for a person.

The data for these estimates will be given by the person. In the future, personal data held by the government or private companies could also be used for tailoring services. (Since Finland is a member of European Union, this will require a sufficient legal basis for the use of personal data. See the section on the GDPR in chapter 5.)

AuroraAI provides a philosophical example of how technology impacts governance practices. Traditionally, the interaction between government and person has taken the form of compulsion. Governments require citizens to do certain things, in certain ways. In AuroraAI, the government-person interaction is based not just on compulsion, but also recommendations or suggestions.

**Ethical considerations**
AuroraAI, however, raises the question of the impact of these algorithmic recommendation systems in public sector services. Will the algorithms start to pre-determine and direct the future of the users by recommending certain services? Are the recommendations based on implicit and hidden ideals of good life? Will these systems impose existing prejudices? How are the systems built to maintain and promote digital inclusivity and equality?

If AI serves to create public services that predefine the standards of “well-being” or “good life” too narrowly, or muddle the government’s roles in wielding power and providing welfare, then the principles of good governance will end up set aside. In AuroraAI, these concerns have been recognized, and their importance has been acknowledged. As a practical solution, an ethics board has been appointed to provide a forum for discussions on the ethical challenges related to the program.

</text-box>

Fairness, accountability, and transparency have come to dominate the AI ethics conversation. They also comprise the name of the largest scientific conference around ethical AI, FAccT. However, as AuroraAI illustrates, questions of “help, welfare, and government-citizen relations” are among the fundamental moral questions directed at any government that aims to deploy AI in its public sector services.

But, these values do not often appear in ethical guidelines. What, then, would it look like to take a perspective of care to AI ethics? According to the ethics of care, this means taking into consideration the complex dependencies and interdependencies between individuals, how the consequences of actions propagate and affect the most vulnerable, and how nature and ecology become entwined in these processes.


<text-box name="Anatomy of An AI System">

An example of this kind of mapping can be seen in the [Anatomy of An AI System](https://anatomyof.ai/img/ai-anatomy-map.pdf) schematic created by researchers Crawford and Joler. The schematic shows the complex and complete interactions that go into creating an AI artefact. It expands outwards from just software to the material processes of creating an AI system; the markets, infrastructures and geological processes involved. This reveals ethically relevant aspects that would otherwise be obscured by the lens provided by AI ethics: the ecological damages of mining and the labor conditions of data processing, for example.

</text-box>

Moving from new perspectives to new practices, the role of citizens and civil society along with companies in the creation of more just AI should be examined. Creating ethical AI in practice means moving on from publishing good intentions to the many ways that societal actors can participate in effecting different futures.

<text-box>

Or, to take another example, let’s look at AlgorithmWatch. AlgorithmWatch tracks the wealth of public and private AI ventures in Europe, analyzes their consequences, and publishes information on how they are progressing and the many ways they are affecting society. The UK has also seen citizen action in the form of protests revolving around the use of predictive grading algorithms as a fix for the difficulties in organizing exams caused by the COVID-19 virus.

</text-box>


The Director of the Ada Lovelace institute Carly Kind calls this the third wave of AI ethics, and suggests we are moving into a new form of societal engagement:

* “Third-wave ethical AI has seen a Dutch Court shut down an algorithmic fraud detection system, students in the UK take to the streets to protest against algorithmically-decided exam results, and US companies voluntarily restrict their sales of facial recognition technology. It is taking us beyond the principled and the technical, to practical mechanisms for rectifying power imbalances and achieving individual and societal justice.”
>**-Carly Kind**

# Conclusion: now it’s your turn

Ethical questions regarding Al Systems pertain to all stages of the Al system lifecycle, understood here to range from research, design, and development to deployment and use – including maintenance, operation, trade, financing, monitoring and evaluation, validation, end-of-use, disassembly, and termination.

In addition, Al actors can be defined as any actors involved in at least one stage of the Al lifecycle, and can refer both to natural and legal persons, such as researchers, programmers, engineers, data scientists, end users, large technology companies, small and medium enterprises, start-ups, universities, and public entities, among others.

<text-box>

* AI systems raise ethical issues that include, but are not limited to, their impact on decision-making, equality, polarization, and well-being.

* AI systems impact societal sectors such as employment and labor, social interaction, healthcare, education, weaponization, transport, and media.

* AI systems cover topics such as freedom of expression, access to information, privacy, democracy, or discrimination.

* AI systems can also change human experience, challenge human agency, raise concerns on the reliability of sources of information, and question the ideal of fundamental dignity.

</text-box>

Now, it is your turn to think about these questions.

<quiz id="95f8a331-d4a2-443a-b155-3ba7dd8679c1"> </quiz>
