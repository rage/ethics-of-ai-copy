---
path: '/sv/chapter-2/2-the-common-good_calculating-consequences'
title: 'Det allmännas bästa – beräkna konsekvenser'
hidden: false
---

<hero-icon heroIcon='chap2'/>

<img src="stk_keksi_hki_biomedicum_0129_cropped.jpg" alt="Illustration"> </img>

Illustration. © Keksi Agency via City of Helsinki / Communications

<styled-text>

Föreställ dig att du är it-ansvarig för Helsingfors stad. Du blir tillfrågad om du tycker att stadens hälsovårdsorganisation ska gå över från reaktiv hälsovård till förebyggande hälsovård. Du läser en rapport. Den berättar om nya sofistikerade maskininlärningssystem som kan hjälpa hälsovårdsinstitutioner att prognostisera möjliga hälsorisker för stadens invånare.

De här metoderna tar fram förutsägelser genom att kombinera och analysera källor från olika sjukvårds- och hälsovårdssystem. Genom att analysera en stor mängd kriteriedata kan högriskpersoner identifieras och prioriteras. Dessa högriskpersoner kan proaktivt bjudas in till ett läkarbesök för att få rätt behandling.

**Fördelar**

Rapporten nämner många fördelar. Genom att förebygga sjukdomar kan till exempel medborgarnas hälsa och livskvalitet med stor sannolikhet förbättras. Det skulle dessutom göra det enklare att uppskatta effekter för att bättre kunna planera grundläggande hälsovårdstjänster. Förebyggande hälsovård kan även kraftigt minska samhälls- och hälsovårdskostnaderna. Rapporten understryker att dessa besparingar kan användas för det allmännas bästa.

**Potentiella problem**

Rapporten innehåller dock även ett antal orosmoment. Systemen medför till exempel ett antal juridiska och etiska problem vad gäller integritet, säkerhet och dataanvändning. Exempelvis lyfter rapporten frågan om var gränsen går mellan godtagbart förebyggande och icke godtagbart intrång. Har staden rätt att använda privata, känsliga sjukvårdsrelaterade uppgifter för att identifiera högriskpatienter? Hur ger medborgarna sitt samtycke, och vad händer med dem som inte ger sitt samtycke? Vad gäller för dem som inte är kapabla att ge sitt samtycke?

Rapporten lyfter även den grundläggande frågan om stadens roll: om staden har information om en potentiell hälsorisk och inte handlar utifrån dessa uppgifter, är staden då skyldig till vårdslöshet? Behandlas medborgarna jämlikt i den fysiska och den digitala världen? Om någon svimmar i verkligheten ringer vi efter ambulans utan att vi har uttryckligt tillstånd att göra det. I den digitala världen kan vi av integritetsskäl vara förhindrade att kontakta medborgare.


Vilka är dina tankar om exemplet ovan? Skulle du som it-ansvarig stödja användandet av förebyggande metoder? Om ditt svar lyder ungefär ”ja, staden bör försöka hitta ett etiskt och juridiskt godtagbart sätt att använda dessa metoder – fördelarna överväger riskerna”, använde du förmodligen ett slags moraliskt resonemang som kallas ”utilitarism”.

</styled-text>

<text-box name="Utilitarismen" icon="exerIcon">

**Utilitarismen** är en samling etiska teorier. Den ser begreppet ”fördelar” som handlingar som maximerar välbefinnandet hos alla inblandade. Utilitarismen är en variant på konsekventialismen, vilken hävdar att endast konsekvenserna av en handling kan avgöra om den är rätt eller fel.

</text-box>

<styled-text>

Enligt utilitaristen är den moraliskt korrekta handlingen den som skapar den bästa balansen av fördelar och skada för alla inblandade. Till skillnad från andra, mer individualistiska typer av konsekventialism (t.ex. egoism) och ojämnt viktad konsekventialism (t.ex. prioritarism), har utilitarismen alla människors bästa i åtanke. Det finns dock många frågor om vilka utilitarister inte är överens, som till exempel huruvida handlingar ska väljas baserat på deras sannolika resultat (handlingsutilitarism) eller om agenter ska följa regler som maximerar nyttan (regelutilitarism). Det råder också delade meningar om huruvida det är den totala (totalutilitarism), genomsnittliga (genomsnittsutilitarism) eller minimala nyttan som ska maximeras.

För utilitarister definieras nyttan – eller fördelen – i termer av välbefinnande eller lycka. Till exempel definierade Jeremy Bentham, utilitarismens fader, nyttan som ”den egenskap … (som) tenderar att skapa fördel, förmån, njutning, gagn, eller lycka … (eller) förhindra att den berörda parten drabbas av skada, smärta, ondska eller olycka”.

Utilitarismen erbjuder en relativt enkel metod för att avgöra om en handling är moraliskt riktig eller inte. Följ dessa steg för att ta reda på vad vi bör göra:

* För det första identifierar vi de olika handlingar vi kan välja.
* För det andra uppskattar vi den nytta och skada som varje handling resulterar i.
* För det tredje väljer vi den handling som ger största möjliga nytta efter att kostnaderna har beaktats.


<img src=../../../src/assets/pqr-cubicle-fs.svg alt="Past, future, presence" style="width: 800px; margin-left: 2em">

Inom utilitarismen hittar vi många intressanta idéer och koncept. Principen ”avtagande marginalnytta” är till exempel användbar för många ändamål. Enligt den här principen minskar ett objekts nytta allteftersom tillgången till objektet ökar (och vice versa).

När du börjar motionsträna är fördelen till en början stor, och resultaten blir snabbt mycket bättre. Men ju längre du tränar, desto mindre effekt får varje individuellt pass. Om du tränar för ofta minskar nyttan och du börjar känna symtomen av att vara övertränad.

Ett annat exempel är att du kan uppleva stor njutning när du äter en karamell. Men om du äter för mycket godis kan det sluta med att du får diabetes. Det är viktigt att vi alltid tänker på den här nyttoparadoxen när vi bedömer konsekvenserna av handlingar. Vad som är det allmännas bästa idag behöver inte vara det i framtiden.

<img src=../../../src/assets/dim-mu.svg alt="Diminishing marginal utility" style="width: 800px; margin-left: 2em">


## Problemen med utilitarismen

Utilitarismen är inte en perfekt lösning för moraliskt beslutsfattande. Den har kritiserats på många olika punkter. Exempelvis kräver utilitaristiska beräkningar att vi tilldelar värden till de fördelar och skador som kommer av vårt handlande, och jämför dem med konsekvenserna av eventuella andra handlingar. Men det är ofta svårt, på gränsen till omöjligt, att i förväg mäta och jämföra värdena av alla relevanta fördelar och kostnader.

</styled-text>


”Risk” används allmänt som ett mått på sannolikheten för fara, eller en fara som inte går att förutse, eller mer tekniskt, sannolikheten för någon resulterande grad av skada. Inom AI-etiken ses skada och risk som något som uppstår p.g.a. design, olämplig tillämpning eller avsiktligt missbruk av teknik. Några typexempel är risker som diskriminering, integritetskränkning, säkerhetsproblem, cyberkrigföring och skadlig hackning. I praktiken är det svårt att jämföra risker och fördelar av följande skäl:

**För det första** påverkas risker och fördelar av värdeförpliktelser, subjektiva och varierande preferenser, praktiska förhållanden samt personliga och kulturella faktorer.

**För det andra** är skada och nytta inte statiska. Marginalnyttan för ett objekt avtar på ett sätt som kan vara svårt att förutse. Dessutom kan en viss skada eller nytta ha olika nyttovärden i olika situationer. Huruvida en snabbare bil kommer att vara mer fördelaktig beror till exempel på den avsedda användningen – om den ska användas som skolbuss bör vi prioritera säkerheten, men om det är en racingbil kan svaret vara ett annat.

**För det tredje** är verklighetssituationer vanligtvis så invecklade att det är svårt att i förväg förutse eller jämföra alla risker och fördelar. Låt oss till exempel titta på möjliga konsekvenser av militärrobotik. Även om dagens militärrobotar till stor del fjärrstyrs eller är halvautonoma kan vi nog förvänta oss att de framöver kommer att vara helt självgående. Enligt vissa uppskattningar minskar användningen av robotar antalet döda och sårade bland civila militärer. Enligt andra uppskattningar minskar de inte alls risken för civila. Statistiken säger att robotvapen i de krig som pågått under 2000-talets första decennier har varit inblandade i att ta livet av såväl soldater som civila. Möjligheten att använda flera olika tekniker – såsom adversariella ändringar (som stoppar en maskins möjlighet att klassificera bilder ordentligt) – för att lura och manipulera automatiska vapen, försvårar situationen eftersom den specifika risken att skada civila ökar. Den övergripande risknivån beror också på hur lätt det blir att förklara krig när det är robotar som tar den största fysiska risken.

**För det fjärde** tar utilitarismen inte andra moraliska aspekter i beaktande. Det är lätt att föreställa sig situationer där framstående teknik skulle skapa stora fördelar för samhällen, men där dess användning skulle ge utrymme för viktiga etiska frågeställningar. Ta till exempel fallet med ett förebyggande hälsovårdssystem. Systemet kan visserligen vara till nytta för många, men vi måste ändå ställa oss frågan om huruvida grundläggande mänskliga rättigheter, såsom integritet, är viktiga. Vad händer med medborgarnas rätt att inte känna till eventuella hälsoproblem? (Många av oss vill säkert veta om vi är i en högriskgrupp, men vad händer om någon inte vill veta? Kan en stad tvinga på dem denna information? Hur kan vi säkerställa att alla har likvärdig åtkomst till de potentiella fördelarna med ett förebyggande system?


<text-box name="Nozicks nyttomonster" icon="philIcon">

En av de största svårigheterna med utilitarismen är frågan om nytta: vad är det egentligen? Rent tekniskt är nytta bara ett mått (en numerisk kvantitet) som beskriver något slags underliggande ”gagn” som vi vill maximera. Ta till exempel njutning eller välbefinnande (som hedonistiska filosofer hävdar är samma sak). Njutning är åtminstone i viss utsträckning en subjektiv upplevelse, och nytta, som mått, ska omvandla den till en siffra som kan jämföras mellan olika subjekt. Det är ett inte helt lätt uppdrag.

Om vi antar att ett sådant mått som nytta faktiskt existerar ger filosofen Robert Nozick oss följande problem. Det finns en varelse kallad nyttomonstret. Dess hedonistiska sinne är utformat så att oavsett resurs så kommer denna varelse att känna större njutning från den än någon annan. Den uppskattar helt enkelt äpplen, bilar, kaffe, frihet osv. mer än vad någon annan gör. Det innebär att varelsen får mer nytta av resurserna, och om vi har ett moraliskt krav på oss att maximera nyttan från de resurser vi har, är slutsatsen enkel att dra: vi måste ge allt vi har till nyttomonstret. Ingenting till någon annan.

Gör detta utilitarismen onjutbar? Kan utilitaristen argumentera för att Nozicks problem egentligen inte är något problem?

</text-box>

<quiz id="78db0071-7571-5c86-9661-ba4a357d3bff"> </quiz>
