---
path: '/sv/chapter-7/3-moving-forward-with-ethics'
title: 'Gå vidare med etik'
hidden: false
---

<hero-icon heroIcon='chap7'/>

<styled-text>



Om vi rör oss bortom etiska riktlinjer, hur ska AI-etiken se ut i framtiden? Vilken typ av samtal om AI-etik bör vi ha, och vilka etiska aktiviteter och metoder ska användas? Den här frågan är inte helt lätt att besvara, men det kan hjälpa att fundera på vad vi hittills inte har talat om när det gäller etiska riktlinjer för AI.

</styled-text>


<text-box name="AuroraAI-programmet" icon="techIcon">

[Finlands nationella program för artificiell intelligens, AuroraAI](https://vm.fi/en/national-artificial-intelligence-programme-auroraai) (2020–2022) samlar modern teknik, väldesignade servicekedjor och en människocentrerad strategi för god förvaltning. Ett av dess syften är att koppla samman den offentliga, privata och tredje sektorns tjänster för att få mer effektiva, flexibla och anpassade offentliga tjänster.

**Så här går det till:**
I AuroraAI-nätverket kopplas en persons behov bättre ihop med tjänster som finns tillgängliga i ett visst område. Den här anpassningen av tjänster baseras på algoritmbaserade rekommendationer som uppskattar vilken som är den mest användbara kombinationen av tjänster för personen i fråga.

De data som används för uppskattningen kommer direkt från personen. I framtiden kan även personuppgifter från myndigheter och privata företag komma att användas för att anpassa tjänster (eftersom Finland är medlem i EU kommer detta att kräva att det finns en tillräcklig juridisk grund för att använda personuppgifter – se avsnittet om dataskyddsförordningen i kapitel 5).

AuroraAI är ett filosofiskt exempel på vilken effekt teknik kan ha på den offentliga förvaltningen. Tidigare har interaktionen mellan förvaltning och medborgare haft ett tvångsmässigt format. Myndigheter kräver att medborgarna gör saker, och att de gör dem på ett visst sätt. I AuroraAI baseras interaktionen mellan myndighet och medborgare inte bara på tvång, utan även på rekommendationer och förslag.

**Etiska överväganden:**
AuroraAI, väcker å andra sidan frågan om vilken effekt dessa algoritmbaserade rekommendationssystem har på offentliga tjänster. Kommer algoritmerna att börja förutbestämma och styra användarnas framtid genom att rekommendera vissa tjänster? Är rekommendationerna baserade på underförstådda och dolda ideal för det goda livet? Kommer systemen att utnyttja befintliga fördomar? Hur är systemen uppbyggda för att upprätthålla och främja digital inkludering och jämlikhet?

Om AI kan användas för att skapa offentliga tjänster som i förväg definierar standarderna för välbefinnande eller ”ett gott liv” på ett alltför begränsat sätt, eller som gör det svårare för myndigheterna att utöva sin makt och tillhandahålla välfärd, kommer det sluta med att principerna för god förvaltning åsidosätts. I AuroraAI har dessa orosmoment erkänts och deras betydelse uppmärksammats. Som praktisk lösning har en etikkommitté upprättats som ett forum för samtal om de etiska utmaningar som är kopplade till programmet.


</text-box>

<styled-text>

Rättvisa, ansvar och transparens har kommit att dominera samtalet om AI-etik. Deras engelska benämningar (fairness, accountability och transparency) bildar också namnet på den största vetenskapliga konferensen om etisk AI: FAccT. Som AuroraAI visar finns dock frågor om ”hjälp, välfärd och relationer mellan myndigheter och medborgare” bland de grundläggande moraliska frågor som alla förvaltningar med avsikt att implementera AI för offentliga tjänster måste besvara.

Dessa värden omnämns dock sällan i etiska riktlinjer. Hur skulle det då se ut om vi såg på AI-etik ur ett omvårdnadsperspektiv? Enligt vårdetiken innebär det att vi behöver ta hänsyn till de komplexa beroenden som finns mellan individer, hur följderna av handlingar sprider sig och drabbar de mest sårbara, och hur natur och ekologi förs in i processerna.

</styled-text>

<text-box name="Ett AI-systems anatomi" icon="techIcon">

Ett exempel på den här typen av mappning ser vi i översikten över [Ett AI-systems anatomi](https://anatomyof.ai/img/ai-anatomy-map.pdf) som tagits fram av forskarna Crawford och Joler. Översikten visar en komplex och fullständig bild av de interaktioner som krävs för att skapa en AI-artefakt. Den sprider sig utåt från en enkel programvara till de materiella processerna för att skapa ett AI-system: marknader, infrastrukturer och geologiska processer. Detta belyser etiskt relevanta aspekter som annars skulle ha dolts av det filter som AI-etiken utgör, som till exempel de ekologiska skadorna från gruvbrytning eller arbetsvillkoren för databehandlare.

</text-box>

<styled-text>

I och med övergången från nya perspektiv till nya rutiner måste medborgarnas och civilsamhällets roll vid sidan av företagens i skapandet av en mer rättvis AI granskas. Att skapa etisk AI i praktiken innebär att gå vidare från publiceringen av goda intentioner för hur olika aktörer i samhället kan delta i förverkligandet av olika möjliga framtider.

</styled-text>
<text-box>

För att ta ett annat exempel kan vi titta på AlgorithmWatch. AlgorithmWatch följer hälsotillståndet för offentliga och privata AI-projekt i Europa, analyserar deras konsekvenser och publicerar information om hur det går för dem och om alla de sätt på vilka de påverkar samhället. I Storbritannien har vi även sett medborgerliga rörelser som protesterat mot användningen av prognostiserande betygsättningsalgoritmer för att ta itu med de svårigheter som covid-19-viruset har orsakat i provplaneringen.

</text-box>

<styled-text>

Rektorn för Ada Lovelace Institute, Carly Kind, kallar detta för den tredje vågen av AI-etik och föreslår att vi går över till en ny typ av samhällsengagemang:

* ”Den tredje vågen av etisk AI har lett till att en nederländsk domstol har stängt ned ett algoritmbaserat bedrägeridetekteringssystem, studerande i Storbritannien protesterar mot algoritmbaserade provresultat och företag i USA begränsar frivilligt sin försäljning av ansiktsigenkänningsteknik. Vi har tagit oss bortom det principbaserade och tekniska, till praktiska mekanismer för att korrigera en ojämn maktbalans och uppnå individuell och samhällelig rättvisa.”
>**-Carly Kind**

## Slutsatser: nu är det din tur

Etiska frågor om Al-system gäller alla stadier i AI-systemets livscykel, vilket här anses omfatta forskning, utformning och utveckling för att kunna driftsätta och använda systemet. Detta inkluderar underhåll, drift, handel, finansiering, övervakning, utvärdering, validering, tagande ur bruk, demontering och kassering.

AI-aktörer kan därutöver definieras som aktörer som är inblandade i minst ett av stadierna i AI-livscykeln. Det kan röra sig om såväl fysiska som juridiska personer, såsom forskare, programmerare, ingenjörer, datavetare, slutanvändare, stora teknikföretag, små och medelstora företag, nystartade företag, universitet samt offentliga institutioner.

</styled-text>

<text-box>

* AI-system väcker etiska frågor gällande bland annat dess effekt på beslutsfattandet, jämlikheten, polariseringen och välbefinnandet.

* AI-system påverkar samhällssektorer som rekrytering och arbete, social interaktion, hälsovård, utbildning, beväpning, transport och media.

* AI-system berör ämnen som yttrandefrihet, åtkomst till information, integritet, demokrati och diskriminering.

* AI-system kan också ändra den mänskliga upplevelsen, utmana människans agens, väcka frågor om informationskällors tillförlitlighet samt frågor om idealet grundläggande värde.

</text-box>

AI utvecklas snabbt. Ingen kan med säkerhet säga hur den kommer att påverka våra liv – det finns fortfarande utrymme att påverka hur den kommer att se ut. Som för nästan all ny teknik finns det stora risker. Men, om artificiell intelligens utvecklas och tillämpas på ett etiskt hållbart sätt kan AI få många positiva effekter – inte bara för individer och samhällen, utan även för planeten i stort. Vilken riktning utvecklingen tar beror helt och hållet på oss.

”Det är valen, inte slumpen, som avgör ditt öde.”
>**-Aristotle**

<img src="./p-p-f-01.svg" alt="Future"> </img>

<quiz id="13024a99-225c-51db-84cf-7ebf0da74b63"> </quiz>

<quiz id="498b0e18-577c-5bda-9425-d70f00baba2d"> </quiz>

<quiz id="3f6f8e29-0ae6-58c2-ab8a-f0abc39fbc2f"> </quiz>

<quiz id="64f2071e-3ac9-50e2-86d9-8c2925866494"> </quiz>
