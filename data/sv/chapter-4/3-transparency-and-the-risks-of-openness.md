---
path: '/sv/chapter-4/3-transparency-and-the-risks-of-openness'
title: 'Transparens och riskerna med öppenhet'
hidden: false
---

<hero-icon heroIcon='chap4'/>

<styled-text>

Transparens antyder ofta ett modernt, etiskt-socialt-juridiskt ”ideal” (Koivisto 2016), en normativ efterfrågan på en acceptabel användning av teknik i våra samhällen. Det är en reflektion om ett öppenhetsideal som kan materialiseras i form av ”öppen styrelseform”, ”öppna data”, ”öppen källa/kod/åtkomst”, och även i form av ”öppen vetenskap” (Larsson, 2020). Det innebär att transparensöverväganden måste göras för att främja en jämn spridning av vetenskapliga framsteg så att fördelarna med AI-utvecklingen blir tillgängliga för alla.

</styled-text>

<text-box>

Paradoxalt nog kan öppenhetsidealet även få farliga konsekvenser. Transparens på sociala medieplattformar har till exempel lett till ett flertal fall av missbruk och demokratirelaterade utmaningar. Transparens kan leda till säkerhetsrisker. Med för stor transparens kan det hända att integritetskänsliga uppgifter hamnar i fel händer. Ju större öppenheten är med algoritmer och data, desto större skada kan de utsättas för. Algoritmer kan hackas och information kan göra AI mer mottaglig för uppsåtliga attacker. Algoritmer kan också bli stulna enbart baserat på deras förklaringar.

</text-box>

<styled-text>

Sammanfattningsvis kan vi säga att även om det finns ett behov av utökad transparens inom AI, så behöver vi också utveckla metoder som kan hjälpa oss att förhindra missbruk. Transparens kan förvisso hjälpa oss att minska de etiska problemen med till exempel rättvisa och ansvar, men den leder också till etiskt relevanta risker. För stor öppenhet i fel sammanhang kan skada den positiva utvecklingen av AI-baserade processer. Sammantaget är det tydligt att idealet med helt transparenta algoritmer måste övervägas noggrant – vi behöver hitta en balans mellan säkerhet och transparens.

</styled-text>

<quiz id="b6c9ef83-6c0f-5f7a-89cc-c084792394b4"> </quiz>
